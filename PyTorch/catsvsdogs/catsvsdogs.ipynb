{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/ubuntu/.cache/torch/hub/pytorch_vision_master\n",
      "Using cache found in /home/ubuntu/.cache/torch/hub/pytorch_vision_master\n"
     ]
    }
   ],
   "source": [
    "model_resnet18 = torch.hub.load('pytorch/vision', 'resnet18', pretrained = True)\n",
    "model_resnet34 = torch.hub.load('pytorch/vision', 'resnet34', pretrained = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model_resnet18.named_parameters():\n",
    "    if(\"bn\" not in name):\n",
    "        param.requires_grad = False\n",
    "\n",
    "for name, param in model_resnet34.named_parameters():\n",
    "    if(\"bn\" not in name):\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "\n",
    "model_resnet18.fc = nn.Sequential(nn.Linear(model_resnet18.fc.in_features, 512),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Dropout(),\n",
    "                                 nn.Linear(512, num_classes))\n",
    "model_resnet34.fc = nn.Sequential(nn.Linear(model_resnet34.fc.in_features, 512),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Dropout(),\n",
    "                                 nn.Linear(512, num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, loss_fn, train_loader, val_loader, epochs=5, device=\"cpu\"):\n",
    "    for epoch in range(epochs):\n",
    "        training_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        model.train()\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            inputs, targets = batch\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            output = model(inputs)\n",
    "            loss = loss_fn(output, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            training_loss += loss.data.item() * inputs.size(0)\n",
    "        training_loss /= len(train_loader.dataset)\n",
    "        \n",
    "        model.eval()\n",
    "        num_correct = 0 \n",
    "        num_examples = 0\n",
    "        for batch in val_loader:\n",
    "            inputs, targets = batch\n",
    "            inputs = inputs.to(device)\n",
    "            output = model(inputs)\n",
    "            targets = targets.to(device)\n",
    "            loss = loss_fn(output,targets) \n",
    "            valid_loss += loss.data.item() * inputs.size(0)\n",
    "                        \n",
    "            correct = torch.eq(torch.max(F.softmax(output, dim=1), dim=1)[1], targets).view(-1)\n",
    "            num_correct += torch.sum(correct).item()\n",
    "            num_examples += correct.shape[0]\n",
    "        valid_loss /= len(val_loader.dataset)\n",
    "\n",
    "        print('Epoch: {}, Training Loss: {:.4f}, Validation Loss: {:.4f}, accuracy = {:.4f}'.format(epoch, training_loss,\n",
    "        valid_loss, num_correct / num_examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "original_path = \"./data/cats-vs-dogs\"\n",
    "subdirs = ['train', 'validation', 'test']\n",
    "for subdir in subdirs:\n",
    "    newdir = os.path.join(original_path, subdir)\n",
    "    for subset in ['cats', 'dogs']:\n",
    "        newsubset = os.path.join(newdir, subset)\n",
    "        os.makedirs(newsubset, exist_ok =True)\n",
    "    \n",
    "original_train_path = \"./data/train\"\n",
    "train_path = \"./data/cats-vs-dogs/train\"\n",
    "validation_path = \"./data/cats-vs-dogs/validation\"\n",
    "test_path = \"./data/cats-vs-dogs/test\"\n",
    "\n",
    "import re\n",
    "import shutil\n",
    "for filename in os.listdir(original_train_path):\n",
    "    index = re.findall(r\"\\d+\", filename)[0]\n",
    "    category = filename.split('.')[0]\n",
    "    src = os.path.join(original_train_path, filename)\n",
    "    newfilename=index+\".jpg\"\n",
    "    if int(index) > 10249:\n",
    "        shutil.move(src, os.path.join(validation_path, category+'s', newfilename))\n",
    "    elif int(index) > 7999:\n",
    "        shutil.move(src, os.path.join(test_path, category+'s', newfilename))\n",
    "    else:\n",
    "        shutil.move(src, os.path.join(train_path, category+'s', newfilename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_dimensions =224\n",
    "\n",
    "img_transforms = transforms.Compose([\n",
    "    transforms.Resize((img_dimensions, img_dimensions)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "img_test_transforms = transforms.Compose([\n",
    "    transforms.Resize((img_dimensions, img_dimensions)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_data_path = train_path\n",
    "train_data = torchvision.datasets.ImageFolder(root=train_data_path, transform=img_transforms)\n",
    "validation_data_path = validation_path\n",
    "validation_data = torchvision.datasets.ImageFolder(root=validation_data_path, \n",
    "                                                  transform=img_test_transforms)\n",
    "\n",
    "test_data_path = test_path\n",
    "test_data = torchvision.datasets.ImageFolder(root=test_data_path, transform=img_test_transforms)\n",
    "\n",
    "num_workers = 6\n",
    "train_data_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, \n",
    "                                                shuffle=True, num_workers = num_workers)\n",
    "validation_data_loader = torch.utils.data.DataLoader(validation_data, batch_size=batch_size,\n",
    "                                               shuffle=False, num_workers = num_workers)\n",
    "test_data_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers = num_workers)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num training images: 16000\n",
      "Num validation images: 4500\n",
      "Num test images: 4500\n"
     ]
    }
   ],
   "source": [
    "print(f'Num training images: {len(train_data_loader.dataset)}')\n",
    "print(f'Num validation images: {len(validation_data_loader.dataset)}')\n",
    "print(f'Num test images: {len(test_data_loader.dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_data_loader:\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print('correct: {:d} total: {:d}'.format(correct, total))\n",
    "    print('accuracy: {:f}'.format(correct/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Training Loss: 0.0897, Validation Loss: 0.0635, accuracy = 0.9744\n",
      "Epoch: 1, Training Loss: 0.0454, Validation Loss: 0.0344, accuracy = 0.9884\n",
      "Epoch: 2, Training Loss: 0.0380, Validation Loss: 0.0335, accuracy = 0.9884\n",
      "Epoch: 3, Training Loss: 0.0363, Validation Loss: 0.0393, accuracy = 0.9844\n",
      "Epoch: 4, Training Loss: 0.0318, Validation Loss: 0.0407, accuracy = 0.9862\n",
      "Epoch: 5, Training Loss: 0.0269, Validation Loss: 0.0434, accuracy = 0.9862\n",
      "Epoch: 6, Training Loss: 0.0228, Validation Loss: 0.0667, accuracy = 0.9798\n",
      "Epoch: 7, Training Loss: 0.0230, Validation Loss: 0.0428, accuracy = 0.9867\n",
      "Epoch: 8, Training Loss: 0.0211, Validation Loss: 0.0504, accuracy = 0.9840\n",
      "Epoch: 9, Training Loss: 0.0188, Validation Loss: 0.0540, accuracy = 0.9853\n",
      "Epoch: 10, Training Loss: 0.0163, Validation Loss: 0.0514, accuracy = 0.9871\n",
      "Epoch: 11, Training Loss: 0.0180, Validation Loss: 0.0533, accuracy = 0.9849\n",
      "Epoch: 12, Training Loss: 0.0176, Validation Loss: 0.0730, accuracy = 0.9804\n",
      "Epoch: 13, Training Loss: 0.0175, Validation Loss: 0.0455, accuracy = 0.9867\n",
      "Epoch: 14, Training Loss: 0.0137, Validation Loss: 0.0564, accuracy = 0.9889\n",
      "Epoch: 15, Training Loss: 0.0156, Validation Loss: 0.0621, accuracy = 0.9831\n",
      "Epoch: 16, Training Loss: 0.0190, Validation Loss: 0.0489, accuracy = 0.9871\n",
      "Epoch: 17, Training Loss: 0.0137, Validation Loss: 0.1203, accuracy = 0.9724\n",
      "Epoch: 18, Training Loss: 0.0126, Validation Loss: 0.0709, accuracy = 0.9831\n",
      "Epoch: 19, Training Loss: 0.0142, Validation Loss: 0.0687, accuracy = 0.9809\n",
      "Epoch: 20, Training Loss: 0.0125, Validation Loss: 0.0480, accuracy = 0.9878\n",
      "Epoch: 21, Training Loss: 0.0102, Validation Loss: 0.0713, accuracy = 0.9827\n",
      "Epoch: 22, Training Loss: 0.0099, Validation Loss: 0.0836, accuracy = 0.9847\n",
      "Epoch: 23, Training Loss: 0.0130, Validation Loss: 0.0764, accuracy = 0.9876\n",
      "Epoch: 24, Training Loss: 0.0171, Validation Loss: 0.0600, accuracy = 0.9849\n",
      "Epoch: 25, Training Loss: 0.0087, Validation Loss: 0.0656, accuracy = 0.9862\n",
      "Epoch: 26, Training Loss: 0.0115, Validation Loss: 0.0568, accuracy = 0.9856\n",
      "Epoch: 27, Training Loss: 0.0125, Validation Loss: 0.0582, accuracy = 0.9862\n",
      "Epoch: 28, Training Loss: 0.0144, Validation Loss: 0.0718, accuracy = 0.9844\n",
      "Epoch: 29, Training Loss: 0.0095, Validation Loss: 0.0759, accuracy = 0.9836\n",
      "Epoch: 30, Training Loss: 0.0101, Validation Loss: 0.0684, accuracy = 0.9844\n",
      "Epoch: 31, Training Loss: 0.0106, Validation Loss: 0.0794, accuracy = 0.9856\n",
      "Epoch: 32, Training Loss: 0.0081, Validation Loss: 0.0861, accuracy = 0.9851\n",
      "Epoch: 33, Training Loss: 0.0063, Validation Loss: 0.0953, accuracy = 0.9840\n",
      "Epoch: 34, Training Loss: 0.0077, Validation Loss: 0.0894, accuracy = 0.9813\n",
      "Epoch: 35, Training Loss: 0.0093, Validation Loss: 0.0781, accuracy = 0.9833\n",
      "Epoch: 36, Training Loss: 0.0090, Validation Loss: 0.0950, accuracy = 0.9840\n",
      "Epoch: 37, Training Loss: 0.0109, Validation Loss: 0.0565, accuracy = 0.9860\n",
      "Epoch: 38, Training Loss: 0.0085, Validation Loss: 0.0720, accuracy = 0.9856\n",
      "Epoch: 39, Training Loss: 0.0091, Validation Loss: 0.0768, accuracy = 0.9851\n",
      "Epoch: 40, Training Loss: 0.0052, Validation Loss: 0.0861, accuracy = 0.9849\n",
      "Epoch: 41, Training Loss: 0.0070, Validation Loss: 0.0963, accuracy = 0.9842\n",
      "Epoch: 42, Training Loss: 0.0084, Validation Loss: 0.0996, accuracy = 0.9807\n",
      "Epoch: 43, Training Loss: 0.0072, Validation Loss: 0.0897, accuracy = 0.9827\n",
      "Epoch: 44, Training Loss: 0.0080, Validation Loss: 0.0849, accuracy = 0.9833\n",
      "Epoch: 45, Training Loss: 0.0073, Validation Loss: 0.0806, accuracy = 0.9833\n",
      "Epoch: 46, Training Loss: 0.0079, Validation Loss: 0.0658, accuracy = 0.9847\n",
      "Epoch: 47, Training Loss: 0.0064, Validation Loss: 0.0709, accuracy = 0.9836\n",
      "Epoch: 48, Training Loss: 0.0103, Validation Loss: 0.0746, accuracy = 0.9853\n",
      "Epoch: 49, Training Loss: 0.0098, Validation Loss: 0.0780, accuracy = 0.9811\n",
      "Epoch: 50, Training Loss: 0.0062, Validation Loss: 0.0742, accuracy = 0.9827\n",
      "Epoch: 51, Training Loss: 0.0068, Validation Loss: 0.0663, accuracy = 0.9840\n",
      "Epoch: 52, Training Loss: 0.0036, Validation Loss: 0.0884, accuracy = 0.9847\n",
      "Epoch: 53, Training Loss: 0.0065, Validation Loss: 0.1105, accuracy = 0.9833\n",
      "Epoch: 54, Training Loss: 0.0095, Validation Loss: 0.0867, accuracy = 0.9836\n",
      "Epoch: 55, Training Loss: 0.0061, Validation Loss: 0.0837, accuracy = 0.9838\n",
      "Epoch: 56, Training Loss: 0.0059, Validation Loss: 0.0880, accuracy = 0.9844\n",
      "Epoch: 57, Training Loss: 0.0058, Validation Loss: 0.1141, accuracy = 0.9827\n",
      "Epoch: 58, Training Loss: 0.0088, Validation Loss: 0.0942, accuracy = 0.9833\n",
      "Epoch: 59, Training Loss: 0.0068, Validation Loss: 0.0857, accuracy = 0.9844\n",
      "Epoch: 60, Training Loss: 0.0065, Validation Loss: 0.1207, accuracy = 0.9804\n",
      "Epoch: 61, Training Loss: 0.0063, Validation Loss: 0.1283, accuracy = 0.9784\n",
      "Epoch: 62, Training Loss: 0.0101, Validation Loss: 0.0621, accuracy = 0.9847\n",
      "Epoch: 63, Training Loss: 0.0057, Validation Loss: 0.1049, accuracy = 0.9798\n",
      "Epoch: 64, Training Loss: 0.0040, Validation Loss: 0.0959, accuracy = 0.9816\n",
      "Epoch: 65, Training Loss: 0.0068, Validation Loss: 0.0899, accuracy = 0.9829\n",
      "Epoch: 66, Training Loss: 0.0047, Validation Loss: 0.1244, accuracy = 0.9807\n",
      "Epoch: 67, Training Loss: 0.0059, Validation Loss: 0.1013, accuracy = 0.9829\n",
      "Epoch: 68, Training Loss: 0.0070, Validation Loss: 0.0775, accuracy = 0.9838\n",
      "Epoch: 69, Training Loss: 0.0050, Validation Loss: 0.0894, accuracy = 0.9838\n",
      "Epoch: 70, Training Loss: 0.0044, Validation Loss: 0.1120, accuracy = 0.9856\n",
      "Epoch: 71, Training Loss: 0.0070, Validation Loss: 0.1098, accuracy = 0.9831\n",
      "Epoch: 72, Training Loss: 0.0083, Validation Loss: 0.0945, accuracy = 0.9820\n",
      "Epoch: 73, Training Loss: 0.0046, Validation Loss: 0.1072, accuracy = 0.9836\n",
      "Epoch: 74, Training Loss: 0.0058, Validation Loss: 0.0992, accuracy = 0.9853\n",
      "Epoch: 75, Training Loss: 0.0037, Validation Loss: 0.1455, accuracy = 0.9804\n",
      "Epoch: 76, Training Loss: 0.0049, Validation Loss: 0.1249, accuracy = 0.9833\n",
      "Epoch: 77, Training Loss: 0.0074, Validation Loss: 0.0829, accuracy = 0.9818\n",
      "Epoch: 78, Training Loss: 0.0081, Validation Loss: 0.1099, accuracy = 0.9813\n",
      "Epoch: 79, Training Loss: 0.0061, Validation Loss: 0.1014, accuracy = 0.9844\n",
      "Epoch: 80, Training Loss: 0.0044, Validation Loss: 0.1209, accuracy = 0.9816\n",
      "Epoch: 81, Training Loss: 0.0085, Validation Loss: 0.1137, accuracy = 0.9802\n",
      "Epoch: 82, Training Loss: 0.0070, Validation Loss: 0.0967, accuracy = 0.9831\n",
      "Epoch: 83, Training Loss: 0.0042, Validation Loss: 0.1050, accuracy = 0.9844\n",
      "Epoch: 84, Training Loss: 0.0031, Validation Loss: 0.1520, accuracy = 0.9800\n",
      "Epoch: 85, Training Loss: 0.0073, Validation Loss: 0.0915, accuracy = 0.9836\n",
      "Epoch: 86, Training Loss: 0.0037, Validation Loss: 0.0998, accuracy = 0.9840\n",
      "Epoch: 87, Training Loss: 0.0046, Validation Loss: 0.1267, accuracy = 0.9822\n",
      "Epoch: 88, Training Loss: 0.0069, Validation Loss: 0.0965, accuracy = 0.9820\n",
      "Epoch: 89, Training Loss: 0.0043, Validation Loss: 0.0954, accuracy = 0.9847\n",
      "Epoch: 90, Training Loss: 0.0042, Validation Loss: 0.1166, accuracy = 0.9840\n",
      "Epoch: 91, Training Loss: 0.0085, Validation Loss: 0.1023, accuracy = 0.9822\n",
      "Epoch: 92, Training Loss: 0.0076, Validation Loss: 0.1177, accuracy = 0.9840\n",
      "Epoch: 93, Training Loss: 0.0058, Validation Loss: 0.0938, accuracy = 0.9840\n",
      "Epoch: 94, Training Loss: 0.0045, Validation Loss: 0.0913, accuracy = 0.9820\n",
      "Epoch: 95, Training Loss: 0.0063, Validation Loss: 0.0907, accuracy = 0.9829\n",
      "Epoch: 96, Training Loss: 0.0028, Validation Loss: 0.1087, accuracy = 0.9829\n",
      "Epoch: 97, Training Loss: 0.0018, Validation Loss: 0.1229, accuracy = 0.9831\n",
      "Epoch: 98, Training Loss: 0.0071, Validation Loss: 0.1225, accuracy = 0.9822\n",
      "Epoch: 99, Training Loss: 0.0034, Validation Loss: 0.1249, accuracy = 0.9827\n"
     ]
    }
   ],
   "source": [
    "model_resnet18.to(device)\n",
    "optimizer = optim.Adam(model_resnet18.parameters(), lr=0.001)\n",
    "train(model_resnet18, optimizer, torch.nn.CrossEntropyLoss(), \n",
    "     train_data_loader, validation_data_loader, epochs = 100, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct: 4427 total: 4500\n",
      "accuracy: 0.983778\n"
     ]
    }
   ],
   "source": [
    "test_model(model_resnet18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Training Loss: 0.0686, Validation Loss: 0.0303, accuracy = 0.9884\n",
      "Epoch: 1, Training Loss: 0.0346, Validation Loss: 0.0345, accuracy = 0.9869\n",
      "Epoch: 2, Training Loss: 0.0253, Validation Loss: 0.0364, accuracy = 0.9869\n",
      "Epoch: 3, Training Loss: 0.0209, Validation Loss: 0.0343, accuracy = 0.9862\n",
      "Epoch: 4, Training Loss: 0.0220, Validation Loss: 0.0424, accuracy = 0.9880\n",
      "Epoch: 5, Training Loss: 0.0185, Validation Loss: 0.0401, accuracy = 0.9849\n",
      "Epoch: 6, Training Loss: 0.0201, Validation Loss: 0.0382, accuracy = 0.9884\n",
      "Epoch: 7, Training Loss: 0.0136, Validation Loss: 0.0471, accuracy = 0.9871\n",
      "Epoch: 8, Training Loss: 0.0171, Validation Loss: 0.0447, accuracy = 0.9871\n",
      "Epoch: 9, Training Loss: 0.0131, Validation Loss: 0.0449, accuracy = 0.9871\n",
      "Epoch: 10, Training Loss: 0.0111, Validation Loss: 0.0461, accuracy = 0.9844\n",
      "Epoch: 11, Training Loss: 0.0151, Validation Loss: 0.0833, accuracy = 0.9722\n",
      "Epoch: 12, Training Loss: 0.0141, Validation Loss: 0.0586, accuracy = 0.9864\n",
      "Epoch: 13, Training Loss: 0.0137, Validation Loss: 0.0401, accuracy = 0.9880\n",
      "Epoch: 14, Training Loss: 0.0093, Validation Loss: 0.0830, accuracy = 0.9831\n",
      "Epoch: 15, Training Loss: 0.0146, Validation Loss: 0.0558, accuracy = 0.9860\n",
      "Epoch: 16, Training Loss: 0.0112, Validation Loss: 0.0608, accuracy = 0.9880\n",
      "Epoch: 17, Training Loss: 0.0105, Validation Loss: 0.0428, accuracy = 0.9873\n",
      "Epoch: 18, Training Loss: 0.0088, Validation Loss: 0.0575, accuracy = 0.9862\n",
      "Epoch: 19, Training Loss: 0.0088, Validation Loss: 0.0557, accuracy = 0.9849\n",
      "Epoch: 20, Training Loss: 0.0078, Validation Loss: 0.0639, accuracy = 0.9873\n",
      "Epoch: 21, Training Loss: 0.0096, Validation Loss: 0.0629, accuracy = 0.9849\n",
      "Epoch: 22, Training Loss: 0.0107, Validation Loss: 0.0611, accuracy = 0.9869\n",
      "Epoch: 23, Training Loss: 0.0113, Validation Loss: 0.0509, accuracy = 0.9849\n",
      "Epoch: 24, Training Loss: 0.0066, Validation Loss: 0.0892, accuracy = 0.9860\n",
      "Epoch: 25, Training Loss: 0.0066, Validation Loss: 0.0768, accuracy = 0.9867\n",
      "Epoch: 26, Training Loss: 0.0077, Validation Loss: 0.0603, accuracy = 0.9858\n",
      "Epoch: 27, Training Loss: 0.0067, Validation Loss: 0.0775, accuracy = 0.9864\n",
      "Epoch: 28, Training Loss: 0.0069, Validation Loss: 0.0804, accuracy = 0.9871\n",
      "Epoch: 29, Training Loss: 0.0110, Validation Loss: 0.0676, accuracy = 0.9849\n",
      "Epoch: 30, Training Loss: 0.0077, Validation Loss: 0.0583, accuracy = 0.9871\n",
      "Epoch: 31, Training Loss: 0.0058, Validation Loss: 0.0745, accuracy = 0.9876\n",
      "Epoch: 32, Training Loss: 0.0084, Validation Loss: 0.0628, accuracy = 0.9880\n",
      "Epoch: 33, Training Loss: 0.0067, Validation Loss: 0.0795, accuracy = 0.9869\n",
      "Epoch: 34, Training Loss: 0.0074, Validation Loss: 0.0781, accuracy = 0.9860\n",
      "Epoch: 35, Training Loss: 0.0074, Validation Loss: 0.0787, accuracy = 0.9844\n",
      "Epoch: 36, Training Loss: 0.0069, Validation Loss: 0.0961, accuracy = 0.9851\n",
      "Epoch: 37, Training Loss: 0.0070, Validation Loss: 0.0677, accuracy = 0.9864\n",
      "Epoch: 38, Training Loss: 0.0034, Validation Loss: 0.1029, accuracy = 0.9860\n",
      "Epoch: 39, Training Loss: 0.0083, Validation Loss: 0.0751, accuracy = 0.9867\n",
      "Epoch: 40, Training Loss: 0.0046, Validation Loss: 0.0920, accuracy = 0.9851\n",
      "Epoch: 41, Training Loss: 0.0069, Validation Loss: 0.0603, accuracy = 0.9878\n",
      "Epoch: 42, Training Loss: 0.0047, Validation Loss: 0.1001, accuracy = 0.9804\n",
      "Epoch: 43, Training Loss: 0.0079, Validation Loss: 0.0616, accuracy = 0.9851\n",
      "Epoch: 44, Training Loss: 0.0061, Validation Loss: 0.0960, accuracy = 0.9840\n",
      "Epoch: 45, Training Loss: 0.0027, Validation Loss: 0.0839, accuracy = 0.9853\n",
      "Epoch: 46, Training Loss: 0.0043, Validation Loss: 0.0895, accuracy = 0.9864\n",
      "Epoch: 47, Training Loss: 0.0086, Validation Loss: 0.0889, accuracy = 0.9840\n",
      "Epoch: 48, Training Loss: 0.0062, Validation Loss: 0.0797, accuracy = 0.9851\n",
      "Epoch: 49, Training Loss: 0.0033, Validation Loss: 0.1047, accuracy = 0.9838\n",
      "Epoch: 50, Training Loss: 0.0084, Validation Loss: 0.0809, accuracy = 0.9849\n",
      "Epoch: 51, Training Loss: 0.0065, Validation Loss: 0.0738, accuracy = 0.9851\n",
      "Epoch: 52, Training Loss: 0.0035, Validation Loss: 0.0994, accuracy = 0.9833\n",
      "Epoch: 53, Training Loss: 0.0060, Validation Loss: 0.0921, accuracy = 0.9840\n",
      "Epoch: 54, Training Loss: 0.0025, Validation Loss: 0.1098, accuracy = 0.9856\n",
      "Epoch: 55, Training Loss: 0.0064, Validation Loss: 0.0970, accuracy = 0.9847\n",
      "Epoch: 56, Training Loss: 0.0111, Validation Loss: 0.0893, accuracy = 0.9862\n",
      "Epoch: 57, Training Loss: 0.0062, Validation Loss: 0.0837, accuracy = 0.9862\n",
      "Epoch: 58, Training Loss: 0.0028, Validation Loss: 0.0989, accuracy = 0.9831\n",
      "Epoch: 59, Training Loss: 0.0036, Validation Loss: 0.0979, accuracy = 0.9853\n",
      "Epoch: 60, Training Loss: 0.0044, Validation Loss: 0.1088, accuracy = 0.9849\n",
      "Epoch: 61, Training Loss: 0.0062, Validation Loss: 0.0955, accuracy = 0.9864\n",
      "Epoch: 62, Training Loss: 0.0045, Validation Loss: 0.1004, accuracy = 0.9856\n",
      "Epoch: 63, Training Loss: 0.0049, Validation Loss: 0.1231, accuracy = 0.9853\n",
      "Epoch: 64, Training Loss: 0.0029, Validation Loss: 0.1161, accuracy = 0.9856\n",
      "Epoch: 65, Training Loss: 0.0099, Validation Loss: 0.1096, accuracy = 0.9833\n",
      "Epoch: 66, Training Loss: 0.0032, Validation Loss: 0.1178, accuracy = 0.9867\n",
      "Epoch: 67, Training Loss: 0.0050, Validation Loss: 0.1110, accuracy = 0.9833\n",
      "Epoch: 68, Training Loss: 0.0048, Validation Loss: 0.1141, accuracy = 0.9833\n",
      "Epoch: 69, Training Loss: 0.0088, Validation Loss: 0.1255, accuracy = 0.9844\n",
      "Epoch: 70, Training Loss: 0.0057, Validation Loss: 0.1221, accuracy = 0.9849\n",
      "Epoch: 71, Training Loss: 0.0023, Validation Loss: 0.1454, accuracy = 0.9844\n",
      "Epoch: 72, Training Loss: 0.0036, Validation Loss: 0.1404, accuracy = 0.9838\n",
      "Epoch: 73, Training Loss: 0.0049, Validation Loss: 0.1384, accuracy = 0.9853\n",
      "Epoch: 74, Training Loss: 0.0041, Validation Loss: 0.1451, accuracy = 0.9853\n",
      "Epoch: 75, Training Loss: 0.0085, Validation Loss: 0.1103, accuracy = 0.9851\n",
      "Epoch: 76, Training Loss: 0.0019, Validation Loss: 0.1195, accuracy = 0.9847\n",
      "Epoch: 77, Training Loss: 0.0056, Validation Loss: 0.1431, accuracy = 0.9844\n",
      "Epoch: 78, Training Loss: 0.0071, Validation Loss: 0.1276, accuracy = 0.9864\n",
      "Epoch: 79, Training Loss: 0.0033, Validation Loss: 0.1360, accuracy = 0.9853\n",
      "Epoch: 80, Training Loss: 0.0018, Validation Loss: 0.1269, accuracy = 0.9842\n",
      "Epoch: 81, Training Loss: 0.0053, Validation Loss: 0.1718, accuracy = 0.9842\n",
      "Epoch: 82, Training Loss: 0.0040, Validation Loss: 0.1254, accuracy = 0.9840\n",
      "Epoch: 83, Training Loss: 0.0028, Validation Loss: 0.1256, accuracy = 0.9844\n",
      "Epoch: 84, Training Loss: 0.0017, Validation Loss: 0.1361, accuracy = 0.9813\n",
      "Epoch: 85, Training Loss: 0.0026, Validation Loss: 0.1427, accuracy = 0.9833\n",
      "Epoch: 86, Training Loss: 0.0053, Validation Loss: 0.1480, accuracy = 0.9800\n",
      "Epoch: 87, Training Loss: 0.0067, Validation Loss: 0.1408, accuracy = 0.9847\n",
      "Epoch: 88, Training Loss: 0.0063, Validation Loss: 0.1353, accuracy = 0.9816\n",
      "Epoch: 89, Training Loss: 0.0018, Validation Loss: 0.1330, accuracy = 0.9836\n",
      "Epoch: 90, Training Loss: 0.0018, Validation Loss: 0.1630, accuracy = 0.9827\n",
      "Epoch: 91, Training Loss: 0.0074, Validation Loss: 0.1257, accuracy = 0.9822\n",
      "Epoch: 92, Training Loss: 0.0019, Validation Loss: 0.1576, accuracy = 0.9838\n",
      "Epoch: 93, Training Loss: 0.0025, Validation Loss: 0.1624, accuracy = 0.9829\n",
      "Epoch: 94, Training Loss: 0.0068, Validation Loss: 0.1148, accuracy = 0.9818\n",
      "Epoch: 95, Training Loss: 0.0038, Validation Loss: 0.1330, accuracy = 0.9849\n",
      "Epoch: 96, Training Loss: 0.0012, Validation Loss: 0.1703, accuracy = 0.9847\n",
      "Epoch: 97, Training Loss: 0.0046, Validation Loss: 0.1687, accuracy = 0.9813\n",
      "Epoch: 98, Training Loss: 0.0076, Validation Loss: 0.1162, accuracy = 0.9842\n",
      "Epoch: 99, Training Loss: 0.0033, Validation Loss: 0.1432, accuracy = 0.9822\n"
     ]
    }
   ],
   "source": [
    "model_resnet34.to(device)\n",
    "optimizer = optim.Adam(model_resnet34.parameters(), lr=0.001)\n",
    "train(model_resnet34, optimizer, torch.nn.CrossEntropyLoss(),\n",
    "      train_data_loader, validation_data_loader, epochs = 100, device =device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct: 4433 total: 4500\n",
      "accuracy: 0.985111\n"
     ]
    }
   ],
   "source": [
    "test_model(model_resnet34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_classes(dir):\n",
    "    classes = os.listdir(dir)\n",
    "    classes.sort()\n",
    "    class_to_idx = {classes[i]: i for i in range(len(classes))}\n",
    "    return classes, class_to_idx\n",
    "\n",
    "def make_prediction(model, filename):\n",
    "    labels, _  = find_classes(test_data_path)\n",
    "    img = Image.open(filename)\n",
    "    img = img_test_transforms(img)\n",
    "    img = img.unsqueeze(0)\n",
    "    prediction = model(img.to(device))\n",
    "    prediction = prediction.argmax()\n",
    "    print(labels[prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dogs\n",
      "cats\n"
     ]
    }
   ],
   "source": [
    "make_prediction(model_resnet34, os.path.join(test_data_path, \"dogs\", \"10245.jpg\"))\n",
    "make_prediction(model_resnet34, os.path.join(test_data_path, \"cats\", \"10245.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/ubuntu/.cache/torch/hub/pytorch_vision_master\n",
      "Using cache found in /home/ubuntu/.cache/torch/hub/pytorch_vision_master\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=512, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(model_resnet18.state_dict(), \"./model_resnet18.pth\")\n",
    "torch.save(model_resnet34.state_dict(), \"./model_resnet34.pth\")\n",
    "\n",
    "resnet18 = torch.hub.load('pytorch/vision', 'resnet18')\n",
    "resnet18.fc = nn.Sequential(nn.Linear(resnet18.fc.in_features, 512),\n",
    "                           nn.ReLU(), nn.Dropout(), \n",
    "                           nn.Linear(512, num_classes))\n",
    "resnet18.load_state_dict(torch.load('./model_resnet18.pth'))\n",
    "resnet18.eval()\n",
    "\n",
    "resnet34 = torch.hub.load('pytorch/vision', 'resnet34')\n",
    "resnet34.fc = nn.Sequential(nn.Linear(resnet34.fc.in_features, 512),\n",
    "                           nn.ReLU(), nn.Dropout(),\n",
    "                           nn.Linear(512, num_classes))\n",
    "resnet34.load_state_dict(torch.load('./model_resnet34.pth'))\n",
    "resnet34.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.988667\n",
      "correct: 4449 total: 4500\n"
     ]
    }
   ],
   "source": [
    "models_ensemble = [resnet18.to(device), resnet34.to(device)]\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_data_loader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        predictions = [i(images).data for i in models_ensemble]\n",
    "        avg_predictions = torch.mean(torch.stack(predictions), dim=0)\n",
    "        _, predicted = torch.max(avg_predictions, 1)\n",
    "        \n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "print('accuracy = {:f}'.format(correct/total))\n",
    "print('correct: {:d} total: {:d}'.format(correct, total))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
